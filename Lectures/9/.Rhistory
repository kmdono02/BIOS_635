error_rates_degrees_df <- do.call("rbind", error_rates_degrees)
# Plot results as function of degree
ggplot(data=error_rates_degrees_df,
mapping=aes(x=degree, y=RMSE, color=factor(split_trial)))+
geom_point()+
geom_line()+
geom_hline(yintercept = min(error_rates_degrees_df$RMSE),
linetype="dashed", color="red")+
geom_vline(xintercept =
which(error_rates_degrees_df$RMSE==min(error_rates_degrees_df$RMSE)),
linetype="dashed", color="red")+
labs(title="RMSE (Root Mean Squared Error) by degree on test set\nBy split number")+
theme_bw()
ggplot(data=error_rates_degrees_df,
mapping=aes(x=degree, y=RMSE, color=factor(split_trial)))+
geom_point()+
geom_line()+
labs(title="RMSE (Root Mean Squared Error) by degree on test set\nBy split number")+
theme_bw()
?sample
wage_data_subset <- wage_data[sample(1:dim(wage_data)[1], size=400, replace=FALSE),]
dim(wage_data_subset)
poly_reg_fit <- list()
error_rates_degrees <- list()
counter <- 1
trials <- 10 # Look at 10 different 60:40 splits
wage_data_subset <- wage_data[sample(1:dim(wage_data)[1], size=400, replace=FALSE),]
for(j in 1:trials){
set.seed(j) # Set seed to get different splits
tt_indicies <- createDataPartition(y=wage_data_subset$wage, p=0.6, list = FALSE)
wage_data_train <- wage_data_subset[tt_indicies,]
wage_data_test <- wage_data_subset[-tt_indicies,]
for(i in 1:length(degrees)){
poly_reg_fit[[counter]] <- lm(wage~poly(age, degrees[i]),
data=wage_data_train)
predict_wages <- predict(poly_reg_fit[[counter]], newdata = wage_data_test)
residuals_wages <- wage_data_test$wage-predict_wages
rmse_poly_reg <- sqrt(mean(residuals_wages^2))
mae_poly_reg <- mean(abs(residuals_wages))
# Save in data frame
error_rates_degrees[[counter]] <-
data.frame("RMSE"=rmse_poly_reg,
"MAE"=mae_poly_reg,
"degree"=degrees[i],
"split_trial"=j)
counter <- counter+1
}
}
degrees
degrees[i]
dim(wage_data_train)
degrees <- 1:10
poly_reg_fit <- list()
error_rates_degrees <- list()
# Fit model for each degree considered, compute RMSE (on training in this ex.)
for(i in 1:length(degrees)){
poly_reg_fit[[i]] <- lm(wage~poly(age, degrees[i]),
data=wage_data)
predict_wages <- predict(poly_reg_fit[[i]])
residuals_wages <- wage_data$wage-predict_wages
rmse_poly_reg <- sqrt(mean(residuals_wages^2))
mae_poly_reg <- mean(abs(residuals_wages))
# Save in data frame
error_rates_degrees[[i]] <-
data.frame("RMSE"=rmse_poly_reg,
"MAE"=mae_poly_reg,
"degree"=degrees[i])
}
# Bind all degree-specific results together into single data frame/table
error_rates_degrees_df <- do.call("rbind", error_rates_degrees)
# Plot results as function of degree
ggplot(data=error_rates_degrees_df,
mapping=aes(x=degrees, y=RMSE))+
geom_point()+
geom_line()+
labs(title="RMSE (Root Mean Squared Error) by degree without data splitting")
poly_reg_fit <- list()
error_rates_degrees <- list()
counter <- 1
trials <- 10 # Look at 10 different 60:40 splits
wage_data_subset <- wage_data[sample(1:dim(wage_data)[1], size=400, replace=FALSE),]
for(j in 1:trials){
set.seed(j) # Set seed to get different splits
tt_indicies <- createDataPartition(y=wage_data_subset$wage, p=0.6, list = FALSE)
wage_data_train <- wage_data_subset[tt_indicies,]
wage_data_test <- wage_data_subset[-tt_indicies,]
for(i in 1:length(degrees)){
poly_reg_fit[[counter]] <- lm(wage~poly(age, degrees[i]),
data=wage_data_train)
predict_wages <- predict(poly_reg_fit[[counter]], newdata = wage_data_test)
residuals_wages <- wage_data_test$wage-predict_wages
rmse_poly_reg <- sqrt(mean(residuals_wages^2))
mae_poly_reg <- mean(abs(residuals_wages))
# Save in data frame
error_rates_degrees[[counter]] <-
data.frame("RMSE"=rmse_poly_reg,
"MAE"=mae_poly_reg,
"degree"=degrees[i],
"split_trial"=j)
counter <- counter+1
}
}
error_rates_degrees_df <- do.call("rbind", error_rates_degrees)
error_rates_degrees_df
ggplot(data=error_rates_degrees_df,
mapping=aes(x=degree, y=RMSE, color=factor(split_trial)))+
geom_point()+
geom_line()+
labs(title="RMSE (Root Mean Squared Error) by degree on test set\nBy split number")+
theme_bw()
ggplot(data=error_rates_degrees_df,
mapping=aes(x=degree, y=log(RMSE), color=factor(split_trial)))+
geom_point()+
geom_line()+
labs(title="RMSE (Root Mean Squared Error) by degree on test set\nBy split number")+
theme_bw()
?createDataPartition
cv_folds <- createFolds(y=wage_data$wage, k=5)
cv_folds
cv_folds <- createFolds(y=wage_data_subset$wage, k=5)
cv_folds$Fold1
# 5 fold CV partitions
cv_folds <- createFolds(y=wage_data_subset$wage, k=5)
# Can see whose in fold 1
cv_folds$Fold1
# Look at dataset for fold 1
wage_data_fold_1 <- wage_data_subset[cv_folds$Fold1,]
paged_table(wage_data_fold_1)
tt_indicies <- createFolds(y=wage_data_subset$wage, k=5)
tt_indicies[[1]]
# Fit model for each degree considered, compute RMSE (on training in this ex.)
poly_reg_fit <- list()
predict_wages <- list()
residuals_wages <- list()
rmse_poly_reg <- list()
mae_poly_reg <- list()
error_rates_degrees <- list()
counter <- 1
trials <- 10 # Look at 10 different 60:40 splits
j=1
set.seed(j) # Set seed to get different splits
tt_indicies <- createFolds(y=wage_data_subset$wage, k=5)
i=1
for(f in 1:length(tt_indicies)){
wage_data_train <- wage_data_subset[tt_indicies[[f]],]
wage_data_test <- wage_data_subset[-tt_indicies[[f]],]
poly_reg_fit[[f]] <- lm(wage~poly(age, degrees[i]),
data=wage_data_train)
predict_wages[[f]] <- predict(poly_reg_fit[[f]], newdata = wage_data_test)
residuals_wages[[f]] <- wage_data_test$wage-predict_wages
rmse_poly_reg[[f]] <- sqrt(mean(residuals_wages^2))
mae_poly_reg[[f]] <- mean(abs(residuals_wages))
}
f
poly_reg_fit <- list()
predict_wages <- list()
residuals_wages <- list()
rmse_poly_reg <- list()
mae_poly_reg <- list()
error_rates_degrees <- list()
wage_data_train <- wage_data_subset[tt_indicies[[f]],]
wage_data_test <- wage_data_subset[-tt_indicies[[f]],]
poly_reg_fit[[f]] <- lm(wage~poly(age, degrees[i]),
data=wage_data_train)
predict(poly_reg_fit[[f]], newdata = wage_data_test)
for(f in 1:length(tt_indicies)){
wage_data_train <- wage_data_subset[tt_indicies[[f]],]
wage_data_test <- wage_data_subset[-tt_indicies[[f]],]
poly_reg_fit[[f]] <- lm(wage~poly(age, degrees[i]),
data=wage_data_train)
predict_wages[[f]] <- predict(poly_reg_fit[[f]], newdata = wage_data_test)
residuals_wages[[f]] <- wage_data_test$wage-predict_wages[[f]]
rmse_poly_reg[[f]] <- sqrt(mean(residuals_wages[[f]]^2))
mae_poly_reg[[f]] <- mean(abs(residuals_wages[[f]]))
}
rmse_poly_reg
data.frame("RMSE"=mean(unlist(rmse_poly_reg)),
"MAE"=mean(unlist(mae_poly_reg)),
"degree"=degrees[i],
"split_trial"=j)
# Fit model for each degree considered, compute RMSE (on training in this ex.)
poly_reg_fit <- list()
predict_wages <- list()
residuals_wages <- list()
rmse_poly_reg <- list()
mae_poly_reg <- list()
error_rates_degrees <- list()
counter <- 1
trials <- 10 # Look at 10 different 60:40 splits
for(j in 1:trials){
set.seed(j) # Set seed to get different splits
tt_indicies <- createFolds(y=wage_data_subset$wage, k=5)
for(i in 1:length(degrees)){
for(f in 1:length(tt_indicies)){
wage_data_train <- wage_data_subset[tt_indicies[[f]],]
wage_data_test <- wage_data_subset[-tt_indicies[[f]],]
poly_reg_fit[[f]] <- lm(wage~poly(age, degrees[i]),
data=wage_data_train)
predict_wages[[f]] <- predict(poly_reg_fit[[f]], newdata = wage_data_test)
residuals_wages[[f]] <- wage_data_test$wage-predict_wages[[f]]
rmse_poly_reg[[f]] <- sqrt(mean(residuals_wages[[f]]^2))
mae_poly_reg[[f]] <- mean(abs(residuals_wages[[f]]))
}
# Save in data frame
error_rates_degrees[[counter]] <-
data.frame("RMSE"=mean(unlist(rmse_poly_reg)),
"MAE"=mean(unlist(mae_poly_reg)),
"degree"=degrees[i],
"split_trial"=j)
counter <- counter+1
}
}
error_rates_degrees_df <- do.call("rbind", error_rates_degrees)
error_rates_degrees_df
ggplot(data=error_rates_degrees_df,
mapping=aes(x=degree, y=log(RMSE), color=factor(split_trial)))+
geom_point()+
geom_line()+
labs(title="RMSE (Root Mean Squared Error) by degree on test set\nBy split number")+
theme_bw()
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE,
fig.width = 6, fig.height = 3)
heart_data <- read_csv(file="../data/heart_disease/Correct_Dataset.csv") %>%
mutate(heart_disease =
relevel(factor(ifelse(Target>0, "Yes", "No")),
ref = "No"))
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE,
fig.width = 6, fig.height = 3)
library(tidyverse)
library(mgcv)
library(splines)
library(ISLR)
library(caret)
library(rmarkdown)
wage_data <- Wage # contained in ISLR package
# Holdout 40% for tesing
tt_indicies <- createDataPartition(y=wage_data$wage, p=0.6, list = FALSE)
wage_data_train <- wage_data[tt_indicies,]
wage_data_test <- wage_data[-tt_indicies,]
# Look at datasets
paged_table(wage_data_train)
paged_table(wage_data_test)
## Set degrees being considered:
degrees <- 1:10
poly_reg_fit <- list()
error_rates_degrees <- list()
# Fit model for each degree considered, compute RMSE (on training in this ex.)
for(i in 1:length(degrees)){
poly_reg_fit[[i]] <- lm(wage~poly(age, degrees[i]),
data=wage_data)
predict_wages <- predict(poly_reg_fit[[i]])
residuals_wages <- wage_data$wage-predict_wages
rmse_poly_reg <- sqrt(mean(residuals_wages^2))
mae_poly_reg <- mean(abs(residuals_wages))
# Save in data frame
error_rates_degrees[[i]] <-
data.frame("RMSE"=rmse_poly_reg,
"MAE"=mae_poly_reg,
"degree"=degrees[i])
}
# Bind all degree-specific results together into single data frame/table
error_rates_degrees_df <- do.call("rbind", error_rates_degrees)
# Plot results as function of degree
ggplot(data=error_rates_degrees_df,
mapping=aes(x=degrees, y=RMSE))+
geom_point()+
geom_line()+
labs(title="RMSE (Root Mean Squared Error) by degree without data splitting")
# Line continuously decreases, though seems improvement after 3 or 4 is minimal
# For better assessment, split into training (60:40 split for ex)
# Fit model for each degree considered, compute RMSE (on training in this ex.)
poly_reg_fit <- list()
error_rates_degrees <- list()
counter <- 1
trials <- 10 # Look at 10 different 60:40 splits
wage_data_subset <- wage_data[sample(1:dim(wage_data)[1], size=400, replace=FALSE),]
for(j in 1:trials){
set.seed(j) # Set seed to get different splits
tt_indicies <- createDataPartition(y=wage_data_subset$wage, p=0.6, list = FALSE)
wage_data_train <- wage_data_subset[tt_indicies,]
wage_data_test <- wage_data_subset[-tt_indicies,]
for(i in 1:length(degrees)){
poly_reg_fit[[counter]] <- lm(wage~poly(age, degrees[i]),
data=wage_data_train)
predict_wages <- predict(poly_reg_fit[[counter]], newdata = wage_data_test)
residuals_wages <- wage_data_test$wage-predict_wages
rmse_poly_reg <- sqrt(mean(residuals_wages^2))
mae_poly_reg <- mean(abs(residuals_wages))
# Save in data frame
error_rates_degrees[[counter]] <-
data.frame("RMSE"=rmse_poly_reg,
"MAE"=mae_poly_reg,
"degree"=degrees[i],
"split_trial"=j)
counter <- counter+1
}
}
# Bind all degree-specific results together into single data frame/table
error_rates_degrees_df <- do.call("rbind", error_rates_degrees)
# Plot results as function of degree
ggplot(data=error_rates_degrees_df,
mapping=aes(x=degree, y=log(RMSE), color=factor(split_trial)))+
geom_point()+
geom_line()+
labs(title="RMSE (Root Mean Squared Error) by degree on test set\nBy split number")+
theme_bw()
# 5 fold CV partitions
cv_folds <- createFolds(y=wage_data_subset$wage, k=5)
# Can see whose in fold 1
cv_folds$Fold1
# Look at dataset for fold 1
wage_data_fold_1 <- wage_data_subset[cv_folds$Fold1,]
paged_table(wage_data_fold_1)
# Fit model for each degree considered, compute RMSE (on training in this ex.)
poly_reg_fit <- list()
predict_wages <- list()
residuals_wages <- list()
rmse_poly_reg <- list()
mae_poly_reg <- list()
error_rates_degrees <- list()
counter <- 1
trials <- 10 # Look at 10 different 60:40 splits
for(j in 1:trials){
set.seed(j) # Set seed to get different splits
tt_indicies <- createFolds(y=wage_data_subset$wage, k=5)
for(i in 1:length(degrees)){
for(f in 1:length(tt_indicies)){
wage_data_train <- wage_data_subset[tt_indicies[[f]],]
wage_data_test <- wage_data_subset[-tt_indicies[[f]],]
poly_reg_fit[[f]] <- lm(wage~poly(age, degrees[i]),
data=wage_data_train)
predict_wages[[f]] <- predict(poly_reg_fit[[f]], newdata = wage_data_test)
residuals_wages[[f]] <- wage_data_test$wage-predict_wages[[f]]
rmse_poly_reg[[f]] <- sqrt(mean(residuals_wages[[f]]^2))
mae_poly_reg[[f]] <- mean(abs(residuals_wages[[f]]))
}
# Save in data frame
error_rates_degrees[[counter]] <-
data.frame("RMSE"=mean(unlist(rmse_poly_reg)),
"MAE"=mean(unlist(mae_poly_reg)),
"degree"=degrees[i],
"split_trial"=j)
counter <- counter+1
}
}
# Bind all degree-specific results together into single data frame/table
error_rates_degrees_df <- do.call("rbind", error_rates_degrees)
# Plot results as function of degree
ggplot(data=error_rates_degrees_df,
mapping=aes(x=degree, y=log(RMSE), color=factor(split_trial)))+
geom_point()+
geom_line()+
labs(title="RMSE (Root Mean Squared Error) by degree using 5-fold CV\nBy split number")+
theme_bw()
heart_data <- read_csv(file="../data/heart_disease/Correct_Dataset.csv") %>%
mutate(heart_disease =
relevel(factor(ifelse(Target>0, "Yes", "No")),
ref = "No"))
tt_indicies <- createFolds(y=heart_data$target, k=5)
tt_indicies <- createFolds(y=heart_data$heart_disease, k=5)
tt_indicies
f=1
heart_data_train <- heart_data[tt_indicies[[f]],]
heart_data_test <- heart_data[-tt_indicies[[f]],]
lda_fit[[f]] <- train(heart_disease~Age+Sex+Chest_Pain+Resting_Blood_Pressure+
Colestrol+MAX_Heart_Rate+Exercised_Induced_Angina,
data = heart_data_train, method = "lda")
lda_fit <- list()
estimted_probs <- list()
lda_fit[[f]] <- train(heart_disease~Age+Sex+Chest_Pain+Resting_Blood_Pressure+
Colestrol+MAX_Heart_Rate+Exercised_Induced_Angina,
data = heart_data_train, method = "lda")
estimted_probs[[f]] <- predict(poly_reg_fit[[f]], newdata = wage_data_test)
accuracy_rates <- list()
pred_heart_disease <-
relevel(factor(ifelse(estimted_probs[[f]]>0.5,
"Yes", "No")), ref = "No")
confusionMatrix(pred_heart_disease,
reference = heart_data_test$heart_disease,
positive = "Yes")
pred_heart_disease
lenth(pred_heart_disease)
length(pred_heart_disease)
length(heart_data_test$heart_disease)
dim(heart_data_test)
dim(heart_data_train)
heart_data_train <- heart_data[-tt_indicies[[f]],]
heart_data_test <- heart_data[tt_indicies[[f]],]
lda_fit[[f]] <- train(heart_disease~Age+Sex+Chest_Pain+Resting_Blood_Pressure+
Colestrol+MAX_Heart_Rate+Exercised_Induced_Angina,
data = heart_data_train, method = "lda")
estimted_probs[[f]] <- predict(lda_fit[[f]], newdata=heart_data_test, type = "prob")$Yes
length(estimted_probs[[f]])
pred_heart_disease <-
relevel(factor(ifelse(estimted_probs[[f]]>0.5,
"Yes", "No")), ref = "No")
# Get accuracy rates from output
accuracy_rates[[f]] <- confusionMatrix(pred_heart_disease,
reference = heart_data_test$heart_disease,
positive = "Yes")
accuracy_rates[[f]]
accuracy_rates[[f]]$table
accuracy_rates[[f]]$byClass
confusionMatrix(pred_heart_disease,
reference = heart_data_test$heart_disease,
positive = "Yes")$byClass
data.frame(confusionMatrix(pred_heart_disease,
reference = heart_data_test$heart_disease,
positive = "Yes")$byClass)
accuracy_rates[[f]]$overall
c(confusionMatrix(pred_heart_disease,
reference = heart_data_test$heart_disease,
positive = "Yes")$byClass,
confusionMatrix(pred_heart_disease,
reference = heart_data_test$heart_disease,
positive = "Yes")$overall,
"fold"=f)
accuracy_rates[[f]] <-
c(confusionMatrix(pred_heart_disease,
reference = heart_data_test$heart_disease,
positive = "Yes")$byClass,
confusionMatrix(pred_heart_disease,
reference = heart_data_test$heart_disease,
positive = "Yes")$overall,
"fold"=f)
heart_data <- read_csv(file="../data/heart_disease/Correct_Dataset.csv") %>%
mutate(heart_disease =
relevel(factor(ifelse(Target>0, "Yes", "No")),
ref = "No"))
# Create lists to hold results
lda_fit <- list()
estimted_probs <- list()
accuracy_rates <- list()
# Create 5 folds
tt_indicies <- createFolds(y=heart_data$heart_disease, k=5)
# Run LDA for each fold, store results
for(f in 1:length(tt_indicies)){
heart_data_train <- heart_data[-tt_indicies[[f]],]
heart_data_test <- heart_data[tt_indicies[[f]],]
lda_fit[[f]] <- train(heart_disease~Age+Sex+Chest_Pain+Resting_Blood_Pressure+
Colestrol+MAX_Heart_Rate+Exercised_Induced_Angina,
data = heart_data_train, method = "lda")
estimted_probs[[f]] <- predict(lda_fit[[f]], newdata=heart_data_test, type = "prob")$Yes
pred_heart_disease <-
relevel(factor(ifelse(estimted_probs[[f]]>0.5,
"Yes", "No")), ref = "No")
# Get accuracy rates from output
accuracy_rates[[f]] <-
c(confusionMatrix(pred_heart_disease,
reference = heart_data_test$heart_disease,
positive = "Yes")$byClass,
confusionMatrix(pred_heart_disease,
reference = heart_data_test$heart_disease,
positive = "Yes")$overall,
"fold"=f)
}
do.call("rbind", accuracy_rates)
data.frame(do.call("rbind", accuracy_rates))
accuracy_df <- data.frame(do.call("rbind", accuracy_rates))
CV_ests <- accuracy_df %>% select(-fold) %>% apply(MARGIN = 2, FUN=mean)
CV_ests
View(CV_ests)
CV_ests <- accuracy_df %>% select(-fold) %>% lapply(MARGIN = 2, FUN=mean)
View(CV_ests)
CV_se <- accuracy_df %>% select(-fold) %>% apply(MARGIN = 2, FUN=sd)
CV_se
CV_mean
CV_mean <- accuracy_df %>% select(-fold) %>% apply(MARGIN = 2, FUN=mean)
CV_mean
heart_data <- read_csv(file="../data/heart_disease/Correct_Dataset.csv") %>%
mutate(heart_disease =
relevel(factor(ifelse(Target>0, "Yes", "No")),
ref = "No"))
# Create lists to hold results
lda_fit <- list()
estimted_probs <- list()
accuracy_rates <- list()
# Create 5 folds
tt_indicies <- createFolds(y=heart_data$heart_disease, k=5)
# Run LDA for each fold, store results
for(f in 1:length(tt_indicies)){
heart_data_train <- heart_data[-tt_indicies[[f]],]
heart_data_test <- heart_data[tt_indicies[[f]],]
lda_fit[[f]] <- train(heart_disease~Age+Sex+Chest_Pain+Resting_Blood_Pressure+
Colestrol+MAX_Heart_Rate+Exercised_Induced_Angina,
data = heart_data_train, method = "lda")
estimted_probs[[f]] <- predict(lda_fit[[f]], newdata=heart_data_test, type = "prob")$Yes
pred_heart_disease <-
relevel(factor(ifelse(estimted_probs[[f]]>0.5,
"Yes", "No")), ref = "No")
# Get accuracy rates from output
accuracy_rates[[f]] <-
c(confusionMatrix(pred_heart_disease,
reference = heart_data_test$heart_disease,
positive = "Yes")$byClass,
confusionMatrix(pred_heart_disease,
reference = heart_data_test$heart_disease,
positive = "Yes")$overall,
"fold"=f)
}
accuracy_df <- data.frame(do.call("rbind", accuracy_rates))
# Compute mean and SE for each measure to get CV mean/SE
CV_mean <- accuracy_df %>% select(-fold) %>% apply(MARGIN = 2, FUN=mean)
CV_se <- accuracy_df %>% select(-fold) %>% apply(MARGIN = 2, FUN=sd)
CV_mean
CV_se
CV_mean <- accuracy_df %>%
select(Sensitivity, Specificity, `Pos.Pred.Value`, `Neg.Pred.Value`, Accuracy) %>%
apply(MARGIN = 2, FUN=mean)
CV_mean
f=1
tt_indicies[[f]]
