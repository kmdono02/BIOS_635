---
title: "BIOS 635 Group 1 Final Project"
author: "Lauren Koval, Liana Manuel, Saaketh Vummalaneni, & Lillian Zhou"
date: "5/4/2021"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE, include = TRUE, fig.width = 10, fig.height = 5)
```

```{r packages, echo=FALSE, eval=TRUE, warning=FALSE, message=FALSE}
library(tidyverse)
library(gtsummary)
library(flextable)
library(caret)
library(randomForest)
library(DMwR)
library(GGally)
library(e1071)
```


```{r clean, echo=TRUE, eval=TRUE, warning=FALSE, message=FALSE, fig.width=16, fig.height=16}
stroke_data <- read_csv("healthcare-dataset-stroke-data.csv", na = c("N/A","NA","", "Unknown")) %>%
  select(-id) %>%
  drop_na()


stroke_data <- stroke_data %>%
  mutate(stroke = as.factor(stroke),
         male = ifelse(gender=="Male",1,0),
         ever_married = ifelse(ever_married=="Yes",1,0), 
         job_child = ifelse(work_type=="children",1,0), 
         job_gov = ifelse(work_type=="Govt_job",1,0),
         job_never = ifelse(work_type=="Never_worked",1,0), 
         job_private = ifelse(work_type=="Private",1,0),
         job_selfempl = ifelse(work_type=="Self-employed",1,0),
         rural = ifelse(Residence_type=="Rural",1,0),
         ever_smoked = ifelse(smoking_status %in% c("formerly smoked", "smokes"), 1, 0)) %>%
  select(-c(gender, work_type, Residence_type, smoking_status,job_never, job_gov, job_child, job_private))


stroke_data <- stroke_data %>% mutate_at(.vars=c("male","ever_married", "job_selfempl", "rural", "ever_smoked", "heart_disease", "hypertension"),function(x) as.factor(x))


hypertension_table <- stroke_data[, c(7, 1:6, 8:11)] %>%
  tbl_summary(by=hypertension, statistic = list(all_continuous() ~ "{mean} ({sd})",all_categorical() ~ "{n} ({p}%)")) %>%
  add_n()%>%
  add_p(test = all_continuous() ~ "aov") %>%
  modify_header(update=list(label~"**Characteristics by Hypertension Status **", stat_1~"Non-Hypertensive", stat_2~"Hypertensive")) %>%
  bold_labels() %>%
  as_flex_table() %>%
  bg(., part = "header", bg = "grey") %>%
  bold(., bold = TRUE, part = "header")

hypertension_table


stroke_table <- stroke_data%>%
  tbl_summary(by=stroke, statistic = list(all_continuous() ~ "{mean} ({sd})",all_categorical() ~ "{n} ({p}%)")) %>%
  add_n()%>%
  add_p(test = all_continuous() ~ "aov") %>%
  modify_header(update=list(label~"**Characteristics by Stroke Status **", stat_1~"No Stroke", stat_2~"Stroke")) %>% 
  bold_labels() %>%
  as_flex_table() %>%
  bg(part="header", bg = "grey") %>%
  bold(bold = TRUE, part = "header")

stroke_table

stroke_data %>% 
  ggpairs(ggplot2::aes(color = stroke), progress=FALSE)

```


```{r logistic_regression, echo=TRUE, eval=TRUE, warning=FALSE, message=FALSE}
set.seed(12)
indices <- createFolds(y=stroke_data$stroke, k=10)
log_fit <- list()
log_accuracy <- list()
props <- list()
results_log_class <- data.frame(accuracy=numeric())
by_class<- data.frame(accuracy=numeric())

for (i in 1:length(indices)){
  stroke_train <- stroke_data[-indices[[i]],]
  stroke_test <- stroke_data[indices[[i]],]
  
  train_smote <- SMOTE(stroke~., data=as.data.frame(stroke_train), perc.under = 150)
  log_fit[[i]] <- glm(stroke ~ ., data=train_smote, family=binomial())

  stroke_test$est_probs_log <- predict(log_fit[[i]], newdata=stroke_test, type = "response")
  stroke_test$pred_log_stroke <- ifelse(stroke_test$est_probs_log>0.5, "1","0")

  per_class_accuracy <- rep(NA, length(levels(stroke_test$stroke)))
  for(l in 1:length(levels(stroke_test$stroke))){
    per_class_accuracy[l] <- 
    stroke_test%>%
    filter(stroke==levels(stroke)[l]) %>%
    summarise(accuracy = sum(pred_log_stroke==levels(stroke)[l])/n()) %>%
    unlist()
          
    names(per_class_accuracy)[l] <- 
    paste0("accuracy_", levels(stroke_test$stroke)[l])
    }
  by_class <- rbind(by_class,per_class_accuracy)
      
  test_metrics <- data.frame(postResample(stroke_test$pred_log_stroke,stroke_test$stroke)) %>%
    rename("value"=`postResample.stroke_test.pred_log_stroke..stroke_test.stroke.`) %>%
    rownames_to_column("metric")
  rownames(test_metrics) <- test_metrics$metric
  test_metrics <- test_metrics %>% select(value)
  test_metrics <- t(test_metrics)
  rownames(test_metrics) <- paste0("cv_fold_",i)
  results_log_class <- rbind(results_log_class,test_metrics)
}


rn <- rownames(results_log_class)

rownames(results_log_class) <- c(rn)

results_log_class <- cbind(results_log_class, by_class)

colnames(results_log_class) <- c("Overall_Accuracy","Kappa", "Class_0_Accuracy", "Class_1_Accuracy")

results_log_class <- results_log_class %>% select(!Kappa)

results_log_class <- rbind(results_log_class, lapply(results_log_class, mean))
results_log_class <- rbind(results_log_class, lapply(results_log_class, sd))

rownames(results_log_class) <- c(rn, "mean","SE")

results_log_class <- results_log_class %>% rownames_to_column(" ") %>% mutate(across(where(is.numeric), ~ round(., digits = 3)))


log_table <- flextable(results_log_class) %>% bold(bold = TRUE, part = "header") %>% bold(bold = TRUE,j=1) %>% bg(i=11:12, bg = "grey")
log_table

```



```{r RF, echo=TRUE, eval=TRUE, warning=FALSE, message=FALSE}
set.seed(12)

individualfolds<- createFolds(y=stroke_data$stroke, k=10)

results_RF_class <- data.frame(accuracy=numeric())
by_class<- data.frame(accuracy=numeric())

n_pred <- dim(stroke_data)[2]-1
n_trees <- c(50,250,500,750)
n_ms <- c(sqrt(n_pred),n_pred/2, 2*sqrt(n_pred), n_pred)

control <- trainControl(method = 'cv',
                        number = 5,
                        search = 'grid')

for(i in 1:length(individualfolds)){
      tune_res <- data.frame(ntree=numeric(), mtry=numeric(), Accuracy=numeric())

      train_data <- stroke_data[-individualfolds[[i]],]
      train_smote <- SMOTE(stroke~., data=as.data.frame(train_data), perc.under = 150)
      
      test_data <- stroke_data[individualfolds[[i]],]
      tunegrid <- expand.grid(.mtry = n_ms) 
      
      for(j in 1:length(n_trees)){
        nt <- n_trees[j]
        rf_tune <- train(stroke~., train_smote, method="rf", trControl=control, tuneGrid=tunegrid, ntree=nt )
        res <- rf_tune$results
        res <- as.data.frame(res)
        res$n <- nt
        tune_res <- rbind(tune_res, res)
      }

      
      best_tune <- tune_res %>% filter(Accuracy==max(Accuracy)) %>% unlist() %>% unname()
      best_tune
      
      tunegrid <- expand.grid(.mtry = best_tune[1])
      RFfit_class <- train(stroke~., train_smote, method="rf", trControl=control, tuneGrid=tunegrid, ntree=best_tune[6])

      test_data$preds <- predict(RFfit_class, test_data)
      
      
      per_class_accuracy <- rep(NA, length(levels(test_data$stroke)))
      for(l in 1:length(levels(test_data$stroke))){
        per_class_accuracy[l] <- 
        test_data%>%
        filter(stroke==levels(stroke)[l]) %>%
        summarise(accuracy = sum(preds==levels(stroke)[l])/n()) %>%
        unlist()
          
        names(per_class_accuracy)[l] <- 
        paste0("accuracy_", levels(test_data$stroke)[l])
      }
      
      by_class <- rbind(by_class,per_class_accuracy)
      
      test_metrics <- data.frame(postResample(test_data$preds,test_data$stroke)) %>%
        rename("value"=`postResample.test_data.preds..test_data.stroke.`) %>%
        rownames_to_column("metric")
      rownames(test_metrics) <- test_metrics$metric
      test_metrics <- test_metrics %>% select(value)
      test_metrics <- t(test_metrics)
      rownames(test_metrics) <- paste0("cv_fold_",i)
      results_RF_class <- rbind(results_RF_class,test_metrics)
      
}

rn <- rownames(results_RF_class)

rownames(results_RF_class) <- c(rn)

results_RF_class <- cbind(results_RF_class, by_class)

colnames(results_RF_class) <- c("Overall_Accuracy","Kappa", "Class_0_Accuracy", "Class_1_Accuracy")

results_RF_class <- results_RF_class %>% select(!Kappa)

results_RF_class <- rbind(results_RF_class, lapply(results_RF_class, mean))
results_RF_class <- rbind(results_RF_class, lapply(results_RF_class, sd))

rownames(results_RF_class) <- c(rn, "mean","SE")

results_RF_class <- results_RF_class %>% rownames_to_column(" ") %>% mutate(across(where(is.numeric), ~ round(., digits = 3)))

RF_table <- flextable(results_RF_class) %>% bold(bold = TRUE, part = "header") %>% bold(bold = TRUE,j=1) %>% bg(i=11:12, bg = "grey")
RF_table

```




```{r knn, echo=TRUE, eval=TRUE, warning=FALSE, message=FALSE}
set.seed(12)

individualfolds<- createFolds(y=stroke_data$stroke, k=10)
results_knn_class <- data.frame(accuracy=numeric())
by_class<- data.frame(accuracy=numeric())


data_set_list <- list()
data_set_list_se <- list()
predict_stroke <- list()



for(i in 1:length(individualfolds)){
  stroke_data_train <- stroke_data[-individualfolds[[i]],]
  stroke_data_test <- stroke_data[individualfolds[[i]],]

  train_smote <- SMOTE(stroke~., data=as.data.frame(stroke_data_train), perc.under = 150)
  
  KNNfit<-train(stroke~., data = train_smote, method = "knn",
              preProcess = c("center","scale"),
              trControl = trainControl(method = "cv", number = 5),
              tuneLength = 5)

  stroke_data_test$predict_stroke <- predict(KNNfit, newdata =
                                               stroke_data_test,type="raw")
  
  
   per_class_accuracy <- rep(NA, length(levels(stroke_data_test$stroke)))
      for(l in 1:length(levels(stroke_data_test$stroke))){
        per_class_accuracy[l] <- 
        stroke_data_test%>%
        filter(stroke==levels(stroke)[l]) %>%
        summarise(accuracy = sum(predict_stroke==levels(stroke)[l])/n()) %>%
        unlist()
          
        names(per_class_accuracy)[l] <- 
        paste0("accuracy_", levels(stroke_data_test$stroke)[l])
      }
      
      by_class <- rbind(by_class,per_class_accuracy)
      
      test_metrics <- data.frame(postResample(stroke_data_test$predict_stroke,stroke_data_test$stroke)) %>%
        rename("value"=`postResample.stroke_data_test.predict_stroke..stroke_data_test.stroke.`) %>%
        rownames_to_column("metric")
      rownames(test_metrics) <- test_metrics$metric
      test_metrics <- test_metrics %>% select(value)
      test_metrics <- t(test_metrics)
      rownames(test_metrics) <- paste0("cv_fold_",i)
      results_knn_class <- rbind(results_knn_class,test_metrics)
  
}

rn <- rownames(results_knn_class)

rownames(results_knn_class) <- c(rn)

results_knn_class <- cbind(results_knn_class, by_class)

colnames(results_knn_class) <- c("Overall_Accuracy","Kappa", "Class_0_Accuracy", "Class_1_Accuracy")

results_knn_class <- results_knn_class %>% select(!Kappa)

results_knn_class <- rbind(results_knn_class, lapply(results_knn_class, mean))
results_knn_class <- rbind(results_knn_class, lapply(results_knn_class, sd))

rownames(results_knn_class) <- c(rn, "mean","SE")

results_knn_class <- results_knn_class %>% rownames_to_column(" ") %>% mutate(across(where(is.numeric), ~ round(., digits = 3)))

knn_table <- flextable(results_knn_class) %>% bold(bold = TRUE, part = "header") %>% bold(bold = TRUE,j=1) %>% bg(i=11:12, bg = "grey")
knn_table
```


```{r SVM, echo=TRUE, eval=TRUE, warning=FALSE, message=FALSE}
set.seed(12)
folds <- createFolds(y=stroke_data$stroke, k=10)
results_svm_class <- data.frame(accuracy=numeric())
by_class<- data.frame(accuracy=numeric())


data_set_list <- list()
data_set_list_se <- list()
predict_stroke <- list()

i=1
for (i in 1:length(folds)){
  stroke_train_pre <- stroke_data[-folds[[i]],]
  stroke_test <- stroke_data[folds[[i]],]
  
  stroke_train <- SMOTE(stroke~., data=as.data.frame(stroke_train_pre), perc.under = 150)

  tune_svm_linear <- 
    tune(svm, stroke~., data=stroke_train, kernel ="linear",
         ranges = list(gamma = c(0.001, 0.05, 0.1), 
                       cost = 1:5,
                       epsilon = seq(from=0.1, to=0.5, by=0.1)))
  

  svm_tuned_linear <- tune_svm_linear$best.model
  stroke_test$predict_svm_linear <- predict(svm_tuned_linear, newdata=stroke_test,
                                   type="response")
  
     per_class_accuracy <- rep(NA, length(levels(stroke_test$stroke)))
      for(l in 1:length(levels(stroke_test$stroke))){
        per_class_accuracy[l] <- 
        stroke_test%>%
        filter(stroke==levels(stroke)[l]) %>%
        summarise(accuracy = sum(predict_svm_linear==levels(stroke)[l])/n()) %>%
        unlist()
          
        names(per_class_accuracy)[l] <- 
        paste0("accuracy_", levels(stroke_test$stroke)[l])
      }
      
      by_class <- rbind(by_class,per_class_accuracy)
      
      test_metrics <- data.frame(postResample(stroke_test$predict_svm_linear,stroke_test$stroke)) %>%
        rename("value"=`postResample.stroke_test.predict_svm_linear..stroke_test.stroke.`) %>%
        rownames_to_column("metric")
      rownames(test_metrics) <- test_metrics$metric
      test_metrics <- test_metrics %>% select(value)
      test_metrics <- t(test_metrics)
      rownames(test_metrics) <- paste0("cv_fold_",i)
      results_svm_class <- rbind(results_svm_class,test_metrics)
  

}


rn <- rownames(results_svm_class)

rownames(results_svm_class) <- c(rn)

results_svm_class <- cbind(results_svm_class, by_class)

colnames(results_svm_class) <- c("Overall_Accuracy","Kappa", "Class_0_Accuracy", "Class_1_Accuracy")

results_svm_class <- results_svm_class %>% select(!Kappa)

results_svm_class <- rbind(results_svm_class, lapply(results_svm_class, mean))
results_svm_class <- rbind(results_svm_class, lapply(results_svm_class, sd))

rownames(results_svm_class) <- c(rn, "mean","SE")

results_svm_class <- results_svm_class %>% rownames_to_column(" ") %>% mutate(across(where(is.numeric), ~ round(., digits = 3)))

svm_table <- flextable(results_svm_class) %>% bold(bold = TRUE, part = "header") %>% bold(bold = TRUE,j=1) %>% bg(i=11:12, bg = "grey")
svm_table


```



```{r composite, echo=TRUE, eval=TRUE, warning=FALSE, message=FALSE}

log_mean <- results_log_class[11,]
log_se <- results_log_class[12,]

rf_mean <- results_RF_class[11,]
rf_se <- results_RF_class[12,]

knn_mean <- results_knn_class[11,]
knn_se <- results_knn_class[12,]

svm_mean <- results_svm_class[11,]
svm_se <- results_svm_class[12,]


means <- rbind(log_mean, rf_mean, knn_mean, svm_mean)
means$model <- c("logistic regression","random forest", "knn", "svm")
means <- means %>% select(model, Overall_Accuracy, Class_0_Accuracy,Class_1_Accuracy)


se <- rbind(log_se, rf_se, knn_se, svm_se)
se <- se %>% rename(Overall_Accuracy_SE=Overall_Accuracy, Class_0_Accuracy_SE=Class_0_Accuracy, Class_1_Accuracy_SE=Class_1_Accuracy)
se <- se %>% select(Overall_Accuracy_SE, Class_0_Accuracy_SE,Class_1_Accuracy_SE)


all <- cbind(means, se)
all <- all %>% select(model, Overall_Accuracy, Overall_Accuracy_SE, Class_0_Accuracy, Class_0_Accuracy_SE, Class_1_Accuracy, Class_1_Accuracy_SE) %>% mutate(across(where(is.numeric), ~ round(., digits = 3)))


final_table <- flextable(all) %>% bold(bold = TRUE, part = "header") %>% bold(bold = TRUE,j=1)
final_table

```
